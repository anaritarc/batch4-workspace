{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f1f108c2efb94d44",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Basic Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4781dbdb443e5573",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Always have your imports at the top\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from hashlib import sha1 # just for grading purposes\n",
    "import json # just for grading purposes\n",
    "\n",
    "from utils import get_dataset, workflow_steps, data_analysis_steps\n",
    "\n",
    "def _hash(obj, salt='none'):\n",
    "    if type(obj) is not str:\n",
    "        obj = json.dumps(obj)\n",
    "    to_encode = obj + salt\n",
    "    return sha1(to_encode.encode()).hexdigest()\n",
    "\n",
    "X, y = get_dataset()  # preloaded dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0736ca1b894afc53",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 1: ~The Larch~ Workflow steps\n",
    "\n",
    "What are the basic workflow steps?\n",
    "\n",
    "<img src=\"media/the_larch.jpg\" width=\"300\" />\n",
    "\n",
    "<p style=\"font-size: 9px; text-align:center\">A larch</p>\n",
    "\n",
    "You probably know them already, but we want you to really internalize them. We've given you a list of steps `workflow_steps`, but it appears that, not only does it have to many steps, some are _probably_ wrong, as well.\n",
    "\n",
    "Select the correct ones and reorder them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a3f3abe0075f1f26",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workflow steps:\n",
      "1 :  Establish a Baseline\n",
      "2 :  Data analysis and preparation\n",
      "3 :  Evaluate results\n",
      "4 :  Watch Netflix\n",
      "5 :  Increase complexity\n",
      "6 :  Get the data\n",
      "7 :  Spam\n",
      "8 :  Iterate\n",
      "9 :  Google Hackathon solutions\n",
      "10 :  Train model\n"
     ]
    }
   ],
   "source": [
    "print(\"Workflow steps:\")\n",
    "for i in range(len(workflow_steps)):\n",
    "    print(i+1, ': ', workflow_steps[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6c8218e1615228f0",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Exercise 1.1. Filter and sort the names of the steps in the workflow_steps list\n",
    "# workflow_steps_answer = [...]\n",
    "\n",
    "# YOUR CODE HERE\n",
    "workflow_steps_answer = [\"Get the data\",\n",
    "                         \"Data analysis and preparation\",\n",
    "                         \"Train model\",\n",
    "                         \"Evaluate results\",\n",
    "                         \"Establish a Baseline\",\n",
    "                         \"Increase complexity\"\n",
    "                         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-d15af97ae329a075",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-99ca7e19f837>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m### BEGIN TESTS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0m_hash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mworkflow_steps_answer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'salt0'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'701e2306da9bfde36382bdb6feb80a354916ebf4'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m### END TESTS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### BEGIN TESTS\n",
    "assert _hash([step.lower() for step in workflow_steps_answer], 'salt0') == '701e2306da9bfde36382bdb6feb80a354916ebf4'\n",
    "### END TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8feaa0f2674908a0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "There are way too many substeps in the Data Analysis and Preparation step to group them all under a single category. We've given you another list of steps: `data_analysis_steps`.\n",
    "\n",
    "Aside from being shuffled, it should be fine but keep an eye out. You never know what to expect..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ee99eb109e66ea78",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Analysis and Preparation steps:\n",
      "1 :  Data analysis\n",
      "2 :  Feature selection\n",
      "3 :  Dealing with data problems\n",
      "4 :  Spanish Inquisition\n",
      "5 :  Feature engineering\n"
     ]
    }
   ],
   "source": [
    "print(\"Data Analysis and Preparation steps:\")\n",
    "for i in range(len(data_analysis_steps)):\n",
    "    print(i+1, ': ', data_analysis_steps[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1e47f7838cbcf13d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Exercise 1.2. Filter and sort the names of the steps in the data_analysis_steps list\n",
    "# data_analysis_steps_answer = [...]\n",
    "\n",
    "# YOUR CODE HERE\n",
    "data_analysis_steps_answer = [\"Data analysis\",\n",
    "                              \"Dealing with data problems\",\n",
    "                              \"Feature engineering\",\n",
    "                              \"Feature selection\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-eb6774d7694e5ada",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN TESTS\n",
    "assert _hash([step.lower() for step in data_analysis_steps_answer], 'salt0') == '658ab90eff4a0cea2bfb51cc89c8db5b4121fa86'\n",
    "### END TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-27c62b7bf227baa7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<p style=\"text-align:center\">That's right! \n",
    "\n",
    "<p style=\"text-align:center\"><b>Nobody</b> expects the Spanish Inquisition!\n",
    "\n",
    "<img src=\"media/spanish_inquisition.gif\" width=\"400\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fb212306fe32d1fc",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Exercise 2: Specific workflow questions\n",
    "\n",
    "Here are some more specific questions about individual workflow steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-53dadb4a6c1cb987",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Exercise 2.1. True or False, you should split your data in a training and test set\n",
    "# split_training_test = ...\n",
    "\n",
    "# Exercise 2.2. True or False, Scikit Pipelines are only useful in production environments\n",
    "# scikit_pipelines_useful = ...\n",
    "\n",
    "# Exercise 2.3. True or False, you should try to make a complex baseline, so you just have \n",
    "#               to make simple improvements on it, later on.\n",
    "# baseline_complex = ...\n",
    "\n",
    "# Exercise 2.4. (optional) True or False, is Brian the Messiah?\n",
    "# is_brian_the_messiah = ...\n",
    "\n",
    "# YOUR CODE HERE\n",
    "split_training_test = True\n",
    "scikit_pipelines_useful = False\n",
    "baseline_complex = False\n",
    "is_brian_the_messiah = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-f1cfeb62360089e3",
     "locked": true,
     "points": 6,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN TESTS\n",
    "assert _hash(split_training_test, 'salt1') == '569b45c42b5c7b490c92692b911af35f575c8a06'\n",
    "assert _hash(scikit_pipelines_useful, 'salt2') == 'ef07576cc7d3bcb2cf29e1a772aec2aad7f59158'\n",
    "assert _hash(baseline_complex, 'salt3') == 'f24a294afb4a09f7f9df9ee13eb18e7d341c439d'\n",
    "### END TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-eb240cb38ac7a823",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<img src=\"media/monty_python_messiah.jpg\" width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5790b6079fcdd3a1",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Scikit Pipelines\n",
    "\n",
    "We've already loaded and splitted a dataset for the following exercises. They're stored in the `X_train`, `X_test`, `y_train` and `y_test` variables.\n",
    "\n",
    "In a perfect world, where you have all your data clean and ready-to-go, you can create your pipeline with just Scikit-learn's Transformers. However, in the real world, that's not the case, and you'll need to create custom Transformers to get the job done. Take a look at the data set, what do you see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>17</th>\n",
       "      <th>leg_1</th>\n",
       "      <th>7</th>\n",
       "      <th>arm_2</th>\n",
       "      <th>2</th>\n",
       "      <th>11</th>\n",
       "      <th>4</th>\n",
       "      <th>16</th>\n",
       "      <th>0</th>\n",
       "      <th>14</th>\n",
       "      <th>...</th>\n",
       "      <th>12</th>\n",
       "      <th>10</th>\n",
       "      <th>15</th>\n",
       "      <th>9</th>\n",
       "      <th>19</th>\n",
       "      <th>18</th>\n",
       "      <th>8</th>\n",
       "      <th>6</th>\n",
       "      <th>arm_0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>1.846707</td>\n",
       "      <td>lapelled</td>\n",
       "      <td>-0.359292</td>\n",
       "      <td>smutty</td>\n",
       "      <td>0.583928</td>\n",
       "      <td>-0.033127</td>\n",
       "      <td>-0.489439</td>\n",
       "      <td>2.526932</td>\n",
       "      <td>-0.517611</td>\n",
       "      <td>1.794558</td>\n",
       "      <td>...</td>\n",
       "      <td>0.590655</td>\n",
       "      <td>0.068456</td>\n",
       "      <td>-1.371117</td>\n",
       "      <td>-0.016423</td>\n",
       "      <td>0.681891</td>\n",
       "      <td>1.044161</td>\n",
       "      <td>0.223788</td>\n",
       "      <td>1.108704</td>\n",
       "      <td>heft</td>\n",
       "      <td>0.506885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1.236093</td>\n",
       "      <td>selenium</td>\n",
       "      <td>0.609138</td>\n",
       "      <td>peripheral</td>\n",
       "      <td>1.091310</td>\n",
       "      <td>-0.705012</td>\n",
       "      <td>-0.111226</td>\n",
       "      <td>0.169361</td>\n",
       "      <td>0.558327</td>\n",
       "      <td>-0.055769</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.092313</td>\n",
       "      <td>-2.281386</td>\n",
       "      <td>0.460938</td>\n",
       "      <td>0.538756</td>\n",
       "      <td>-0.735530</td>\n",
       "      <td>-0.903908</td>\n",
       "      <td>0.076005</td>\n",
       "      <td>-0.316408</td>\n",
       "      <td>ineffective</td>\n",
       "      <td>1.896911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.959271</td>\n",
       "      <td>headmen</td>\n",
       "      <td>-0.767348</td>\n",
       "      <td>Aventine</td>\n",
       "      <td>2.153182</td>\n",
       "      <td>-0.108760</td>\n",
       "      <td>0.024510</td>\n",
       "      <td>0.097676</td>\n",
       "      <td>0.690144</td>\n",
       "      <td>0.401712</td>\n",
       "      <td>...</td>\n",
       "      <td>0.872321</td>\n",
       "      <td>-2.009185</td>\n",
       "      <td>-1.248690</td>\n",
       "      <td>0.224092</td>\n",
       "      <td>1.451144</td>\n",
       "      <td>0.497998</td>\n",
       "      <td>-0.401220</td>\n",
       "      <td>0.183342</td>\n",
       "      <td>stank</td>\n",
       "      <td>2.357902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>-0.603985</td>\n",
       "      <td>stratus</td>\n",
       "      <td>-0.155677</td>\n",
       "      <td>bract</td>\n",
       "      <td>0.086590</td>\n",
       "      <td>1.006293</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.471645</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.576892</td>\n",
       "      <td>...</td>\n",
       "      <td>1.167782</td>\n",
       "      <td>-0.575002</td>\n",
       "      <td>-0.149518</td>\n",
       "      <td>0.529804</td>\n",
       "      <td>0.371146</td>\n",
       "      <td>-0.203045</td>\n",
       "      <td>-1.129707</td>\n",
       "      <td>0.254421</td>\n",
       "      <td>sat</td>\n",
       "      <td>0.588465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>-0.415288</td>\n",
       "      <td>test</td>\n",
       "      <td>2.270693</td>\n",
       "      <td>foothold</td>\n",
       "      <td>0.632782</td>\n",
       "      <td>0.018418</td>\n",
       "      <td>-1.478586</td>\n",
       "      <td>0.235615</td>\n",
       "      <td>0.326927</td>\n",
       "      <td>1.676437</td>\n",
       "      <td>...</td>\n",
       "      <td>0.181866</td>\n",
       "      <td>-2.003477</td>\n",
       "      <td>-1.373141</td>\n",
       "      <td>0.829406</td>\n",
       "      <td>0.338496</td>\n",
       "      <td>1.143754</td>\n",
       "      <td>-0.219101</td>\n",
       "      <td>0.248221</td>\n",
       "      <td>appliance</td>\n",
       "      <td>2.404373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>-0.553588</td>\n",
       "      <td>coprocessor</td>\n",
       "      <td>1.628397</td>\n",
       "      <td>deconvolve</td>\n",
       "      <td>0.568983</td>\n",
       "      <td>0.043811</td>\n",
       "      <td>-0.803675</td>\n",
       "      <td>-0.088282</td>\n",
       "      <td>0.963879</td>\n",
       "      <td>-0.147002</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.379128</td>\n",
       "      <td>-1.820377</td>\n",
       "      <td>0.655741</td>\n",
       "      <td>-0.557492</td>\n",
       "      <td>1.677701</td>\n",
       "      <td>1.639117</td>\n",
       "      <td>2.210523</td>\n",
       "      <td>-0.203580</td>\n",
       "      <td>shopworn</td>\n",
       "      <td>1.393983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.353166</td>\n",
       "      <td>Debby</td>\n",
       "      <td>-0.295401</td>\n",
       "      <td>chimney</td>\n",
       "      <td>0.338484</td>\n",
       "      <td>-0.079641</td>\n",
       "      <td>0.579633</td>\n",
       "      <td>1.187386</td>\n",
       "      <td>-1.062394</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.168461</td>\n",
       "      <td>2.529834</td>\n",
       "      <td>0.884395</td>\n",
       "      <td>-0.187144</td>\n",
       "      <td>0.194384</td>\n",
       "      <td>0.325796</td>\n",
       "      <td>0.428307</td>\n",
       "      <td>1.317598</td>\n",
       "      <td>inferring</td>\n",
       "      <td>-2.683180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>-1.438278</td>\n",
       "      <td>shrub</td>\n",
       "      <td>-0.668144</td>\n",
       "      <td>Erich</td>\n",
       "      <td>0.919229</td>\n",
       "      <td>-0.291811</td>\n",
       "      <td>-0.426358</td>\n",
       "      <td>0.298753</td>\n",
       "      <td>0.883110</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.873298</td>\n",
       "      <td>1.572337</td>\n",
       "      <td>0.778140</td>\n",
       "      <td>-0.180480</td>\n",
       "      <td>0.113270</td>\n",
       "      <td>1.148446</td>\n",
       "      <td>-0.077837</td>\n",
       "      <td>1.080048</td>\n",
       "      <td>yuh</td>\n",
       "      <td>-1.762549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.992042</td>\n",
       "      <td>walkover</td>\n",
       "      <td>-0.755745</td>\n",
       "      <td>young</td>\n",
       "      <td>-0.174960</td>\n",
       "      <td>0.388579</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.919076</td>\n",
       "      <td>-0.006071</td>\n",
       "      <td>2.493000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.536510</td>\n",
       "      <td>-1.755186</td>\n",
       "      <td>0.717686</td>\n",
       "      <td>0.081829</td>\n",
       "      <td>-0.668090</td>\n",
       "      <td>0.321698</td>\n",
       "      <td>0.838491</td>\n",
       "      <td>-0.898468</td>\n",
       "      <td>Brighton</td>\n",
       "      <td>1.308576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>-1.356582</td>\n",
       "      <td>calf</td>\n",
       "      <td>-0.035641</td>\n",
       "      <td>percussion</td>\n",
       "      <td>0.466430</td>\n",
       "      <td>-2.424240</td>\n",
       "      <td>0.794265</td>\n",
       "      <td>-1.562546</td>\n",
       "      <td>0.736844</td>\n",
       "      <td>0.884045</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.615132</td>\n",
       "      <td>0.480502</td>\n",
       "      <td>0.308773</td>\n",
       "      <td>0.066991</td>\n",
       "      <td>0.293558</td>\n",
       "      <td>-1.254289</td>\n",
       "      <td>-0.281328</td>\n",
       "      <td>1.164739</td>\n",
       "      <td>earthen</td>\n",
       "      <td>-0.568113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.909417</td>\n",
       "      <td>scion</td>\n",
       "      <td>0.562969</td>\n",
       "      <td>invasion</td>\n",
       "      <td>-1.398568</td>\n",
       "      <td>-0.007973</td>\n",
       "      <td>-0.875618</td>\n",
       "      <td>-1.037246</td>\n",
       "      <td>0.077368</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.650643</td>\n",
       "      <td>-1.098317</td>\n",
       "      <td>-0.397696</td>\n",
       "      <td>1.523124</td>\n",
       "      <td>0.926178</td>\n",
       "      <td>-1.382800</td>\n",
       "      <td>-0.861284</td>\n",
       "      <td>-0.487125</td>\n",
       "      <td>moneymake</td>\n",
       "      <td>1.170598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.546734</td>\n",
       "      <td>fragmentation</td>\n",
       "      <td>-0.366824</td>\n",
       "      <td>Reagan</td>\n",
       "      <td>-0.238932</td>\n",
       "      <td>-1.006543</td>\n",
       "      <td>-0.999302</td>\n",
       "      <td>1.296995</td>\n",
       "      <td>1.317115</td>\n",
       "      <td>1.139879</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.391758</td>\n",
       "      <td>0.680573</td>\n",
       "      <td>0.631746</td>\n",
       "      <td>-2.121855</td>\n",
       "      <td>0.840620</td>\n",
       "      <td>-0.504775</td>\n",
       "      <td>-0.118069</td>\n",
       "      <td>-0.922410</td>\n",
       "      <td>bifurcate</td>\n",
       "      <td>-0.885418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>-0.977555</td>\n",
       "      <td>SW</td>\n",
       "      <td>0.751387</td>\n",
       "      <td>value</td>\n",
       "      <td>0.099332</td>\n",
       "      <td>-0.592394</td>\n",
       "      <td>-0.576771</td>\n",
       "      <td>-0.238948</td>\n",
       "      <td>0.048522</td>\n",
       "      <td>-0.863991</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.669405</td>\n",
       "      <td>-1.693028</td>\n",
       "      <td>-0.838070</td>\n",
       "      <td>0.270457</td>\n",
       "      <td>0.500917</td>\n",
       "      <td>0.755391</td>\n",
       "      <td>-0.830950</td>\n",
       "      <td>0.543360</td>\n",
       "      <td>neuralgia</td>\n",
       "      <td>1.897924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>1.187679</td>\n",
       "      <td>Exxon</td>\n",
       "      <td>0.201160</td>\n",
       "      <td>shamrock</td>\n",
       "      <td>-0.464617</td>\n",
       "      <td>1.615376</td>\n",
       "      <td>-0.903702</td>\n",
       "      <td>0.403730</td>\n",
       "      <td>1.217159</td>\n",
       "      <td>-0.322320</td>\n",
       "      <td>...</td>\n",
       "      <td>0.283288</td>\n",
       "      <td>0.964233</td>\n",
       "      <td>0.193754</td>\n",
       "      <td>0.998311</td>\n",
       "      <td>-1.179040</td>\n",
       "      <td>0.324359</td>\n",
       "      <td>1.521316</td>\n",
       "      <td>-0.258905</td>\n",
       "      <td>commissary</td>\n",
       "      <td>-0.963142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>-0.303180</td>\n",
       "      <td>tribesman</td>\n",
       "      <td>-1.616311</td>\n",
       "      <td>fleet</td>\n",
       "      <td>0.799942</td>\n",
       "      <td>0.738810</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.367287</td>\n",
       "      <td>-0.935439</td>\n",
       "      <td>0.615367</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.053682</td>\n",
       "      <td>-0.150138</td>\n",
       "      <td>-0.053969</td>\n",
       "      <td>-0.535963</td>\n",
       "      <td>-0.019420</td>\n",
       "      <td>-0.349317</td>\n",
       "      <td>1.085982</td>\n",
       "      <td>-1.067803</td>\n",
       "      <td>plural</td>\n",
       "      <td>0.159855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.968344</td>\n",
       "      <td>inkling</td>\n",
       "      <td>-1.334025</td>\n",
       "      <td>kingpin</td>\n",
       "      <td>0.105376</td>\n",
       "      <td>-0.988591</td>\n",
       "      <td>-0.982487</td>\n",
       "      <td>-0.989628</td>\n",
       "      <td>0.179894</td>\n",
       "      <td>-1.103589</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.601368</td>\n",
       "      <td>-0.348985</td>\n",
       "      <td>1.303736</td>\n",
       "      <td>0.918317</td>\n",
       "      <td>0.550052</td>\n",
       "      <td>-0.224633</td>\n",
       "      <td>1.392002</td>\n",
       "      <td>0.319782</td>\n",
       "      <td>compensable</td>\n",
       "      <td>-0.222100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.288659</td>\n",
       "      <td>amethystine</td>\n",
       "      <td>-0.827231</td>\n",
       "      <td>heartfelt</td>\n",
       "      <td>0.322719</td>\n",
       "      <td>-1.448084</td>\n",
       "      <td>-0.019016</td>\n",
       "      <td>0.857660</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.407464</td>\n",
       "      <td>...</td>\n",
       "      <td>0.519347</td>\n",
       "      <td>-1.360456</td>\n",
       "      <td>-0.941163</td>\n",
       "      <td>0.310908</td>\n",
       "      <td>-0.018513</td>\n",
       "      <td>-1.002529</td>\n",
       "      <td>-0.213447</td>\n",
       "      <td>1.532739</td>\n",
       "      <td>Kabul</td>\n",
       "      <td>1.636312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>-0.487911</td>\n",
       "      <td>transshipping</td>\n",
       "      <td>-0.605715</td>\n",
       "      <td>Rockwell</td>\n",
       "      <td>2.157308</td>\n",
       "      <td>-0.172946</td>\n",
       "      <td>-0.605616</td>\n",
       "      <td>-0.669073</td>\n",
       "      <td>-1.371901</td>\n",
       "      <td>1.711708</td>\n",
       "      <td>...</td>\n",
       "      <td>0.742095</td>\n",
       "      <td>-0.782841</td>\n",
       "      <td>1.137462</td>\n",
       "      <td>1.471170</td>\n",
       "      <td>0.677926</td>\n",
       "      <td>1.826010</td>\n",
       "      <td>-1.613561</td>\n",
       "      <td>0.299293</td>\n",
       "      <td>Noah</td>\n",
       "      <td>0.244121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>2.252436</td>\n",
       "      <td>patrolled</td>\n",
       "      <td>-0.324831</td>\n",
       "      <td>cantle</td>\n",
       "      <td>0.981765</td>\n",
       "      <td>-1.096275</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.638962</td>\n",
       "      <td>1.594505</td>\n",
       "      <td>-1.440051</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.499406</td>\n",
       "      <td>-1.032233</td>\n",
       "      <td>0.996309</td>\n",
       "      <td>-0.991392</td>\n",
       "      <td>-0.688150</td>\n",
       "      <td>1.009817</td>\n",
       "      <td>-0.846961</td>\n",
       "      <td>2.290943</td>\n",
       "      <td>nature</td>\n",
       "      <td>0.531047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>-0.971614</td>\n",
       "      <td>bowie</td>\n",
       "      <td>-0.656894</td>\n",
       "      <td>Pablo</td>\n",
       "      <td>1.200414</td>\n",
       "      <td>1.301741</td>\n",
       "      <td>-0.365322</td>\n",
       "      <td>2.013387</td>\n",
       "      <td>0.032004</td>\n",
       "      <td>1.561511</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.046911</td>\n",
       "      <td>-2.026321</td>\n",
       "      <td>0.552535</td>\n",
       "      <td>0.459972</td>\n",
       "      <td>-1.347126</td>\n",
       "      <td>0.184680</td>\n",
       "      <td>-0.753418</td>\n",
       "      <td>0.536653</td>\n",
       "      <td>dyeing</td>\n",
       "      <td>1.625375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>-0.083106</td>\n",
       "      <td>lulu</td>\n",
       "      <td>0.760056</td>\n",
       "      <td>airborne</td>\n",
       "      <td>-1.504720</td>\n",
       "      <td>0.043602</td>\n",
       "      <td>-0.429302</td>\n",
       "      <td>-0.611769</td>\n",
       "      <td>-0.622649</td>\n",
       "      <td>1.695051</td>\n",
       "      <td>...</td>\n",
       "      <td>0.082440</td>\n",
       "      <td>1.279890</td>\n",
       "      <td>0.663523</td>\n",
       "      <td>-0.742471</td>\n",
       "      <td>-1.406317</td>\n",
       "      <td>-0.692421</td>\n",
       "      <td>0.194607</td>\n",
       "      <td>-1.457551</td>\n",
       "      <td>upkeep</td>\n",
       "      <td>-1.447232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>-2.198806</td>\n",
       "      <td>objectify</td>\n",
       "      <td>-0.502054</td>\n",
       "      <td>their</td>\n",
       "      <td>0.440014</td>\n",
       "      <td>0.132970</td>\n",
       "      <td>-0.555200</td>\n",
       "      <td>1.565524</td>\n",
       "      <td>1.195047</td>\n",
       "      <td>-0.700121</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.021233</td>\n",
       "      <td>1.537036</td>\n",
       "      <td>-0.798648</td>\n",
       "      <td>-0.558922</td>\n",
       "      <td>-1.448014</td>\n",
       "      <td>1.881157</td>\n",
       "      <td>-1.523187</td>\n",
       "      <td>0.708356</td>\n",
       "      <td>Clausen</td>\n",
       "      <td>-1.075251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.243339</td>\n",
       "      <td>multiplicative</td>\n",
       "      <td>0.352055</td>\n",
       "      <td>otherworld</td>\n",
       "      <td>-0.241236</td>\n",
       "      <td>0.243801</td>\n",
       "      <td>-1.525525</td>\n",
       "      <td>1.846637</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.564079</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.560704</td>\n",
       "      <td>-0.722168</td>\n",
       "      <td>0.650201</td>\n",
       "      <td>-0.045586</td>\n",
       "      <td>-0.691908</td>\n",
       "      <td>0.872457</td>\n",
       "      <td>1.443765</td>\n",
       "      <td>frambesia</td>\n",
       "      <td>-1.128686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.186609</td>\n",
       "      <td>Iran</td>\n",
       "      <td>0.194090</td>\n",
       "      <td>warplane</td>\n",
       "      <td>-0.446434</td>\n",
       "      <td>-1.359856</td>\n",
       "      <td>-0.095296</td>\n",
       "      <td>0.249384</td>\n",
       "      <td>0.645484</td>\n",
       "      <td>0.746254</td>\n",
       "      <td>...</td>\n",
       "      <td>1.073632</td>\n",
       "      <td>0.826007</td>\n",
       "      <td>-1.027544</td>\n",
       "      <td>-0.307778</td>\n",
       "      <td>0.607897</td>\n",
       "      <td>0.279022</td>\n",
       "      <td>2.163255</td>\n",
       "      <td>-1.026515</td>\n",
       "      <td>choosy</td>\n",
       "      <td>-0.329294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>1.001046</td>\n",
       "      <td>runabout</td>\n",
       "      <td>0.677875</td>\n",
       "      <td>certitude</td>\n",
       "      <td>-2.703232</td>\n",
       "      <td>0.950308</td>\n",
       "      <td>0.975198</td>\n",
       "      <td>-0.927353</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.654076</td>\n",
       "      <td>1.372711</td>\n",
       "      <td>0.500477</td>\n",
       "      <td>0.070052</td>\n",
       "      <td>0.189582</td>\n",
       "      <td>0.501094</td>\n",
       "      <td>-0.168822</td>\n",
       "      <td>-1.830633</td>\n",
       "      <td>cacao</td>\n",
       "      <td>-1.464473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>-1.211016</td>\n",
       "      <td>wattage</td>\n",
       "      <td>0.047399</td>\n",
       "      <td>horn</td>\n",
       "      <td>-0.651836</td>\n",
       "      <td>-0.662624</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.259723</td>\n",
       "      <td>-0.763259</td>\n",
       "      <td>0.570599</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.559849</td>\n",
       "      <td>-1.113279</td>\n",
       "      <td>-1.627542</td>\n",
       "      <td>-0.066080</td>\n",
       "      <td>-1.661520</td>\n",
       "      <td>-1.804882</td>\n",
       "      <td>-0.384556</td>\n",
       "      <td>everything</td>\n",
       "      <td>1.890331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>-0.202193</td>\n",
       "      <td>disburse</td>\n",
       "      <td>1.098777</td>\n",
       "      <td>encryption</td>\n",
       "      <td>-0.217681</td>\n",
       "      <td>0.812862</td>\n",
       "      <td>1.277665</td>\n",
       "      <td>-0.020902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.629629</td>\n",
       "      <td>...</td>\n",
       "      <td>0.825416</td>\n",
       "      <td>-1.411759</td>\n",
       "      <td>-0.844677</td>\n",
       "      <td>0.747294</td>\n",
       "      <td>0.547097</td>\n",
       "      <td>-0.591571</td>\n",
       "      <td>-0.560181</td>\n",
       "      <td>0.813510</td>\n",
       "      <td>numb</td>\n",
       "      <td>1.643195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.689188</td>\n",
       "      <td>woodchuck</td>\n",
       "      <td>0.197911</td>\n",
       "      <td>systematic</td>\n",
       "      <td>1.735964</td>\n",
       "      <td>0.059630</td>\n",
       "      <td>1.317394</td>\n",
       "      <td>1.049553</td>\n",
       "      <td>0.698223</td>\n",
       "      <td>-0.646937</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.651418</td>\n",
       "      <td>0.852392</td>\n",
       "      <td>-1.106450</td>\n",
       "      <td>0.895193</td>\n",
       "      <td>2.075261</td>\n",
       "      <td>0.197600</td>\n",
       "      <td>0.393485</td>\n",
       "      <td>-0.483886</td>\n",
       "      <td>semper</td>\n",
       "      <td>-0.320670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.752270</td>\n",
       "      <td>Textron</td>\n",
       "      <td>1.271555</td>\n",
       "      <td>equidistant</td>\n",
       "      <td>0.935678</td>\n",
       "      <td>-0.254977</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.342688</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.503993</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.154661</td>\n",
       "      <td>-1.032605</td>\n",
       "      <td>1.246085</td>\n",
       "      <td>-1.110576</td>\n",
       "      <td>-0.777817</td>\n",
       "      <td>1.091507</td>\n",
       "      <td>-1.129052</td>\n",
       "      <td>Keenan</td>\n",
       "      <td>-0.628041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-0.224765</td>\n",
       "      <td>Berniece</td>\n",
       "      <td>-1.801980</td>\n",
       "      <td>banish</td>\n",
       "      <td>-1.170113</td>\n",
       "      <td>-0.388177</td>\n",
       "      <td>-2.553921</td>\n",
       "      <td>0.949554</td>\n",
       "      <td>0.160574</td>\n",
       "      <td>0.170416</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.808045</td>\n",
       "      <td>1.134462</td>\n",
       "      <td>0.436938</td>\n",
       "      <td>-1.366879</td>\n",
       "      <td>0.934320</td>\n",
       "      <td>0.003046</td>\n",
       "      <td>0.759155</td>\n",
       "      <td>emptyhanded</td>\n",
       "      <td>0.268438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>-0.978764</td>\n",
       "      <td>ineluctable</td>\n",
       "      <td>0.377300</td>\n",
       "      <td>metallurgic</td>\n",
       "      <td>-0.444293</td>\n",
       "      <td>-0.459361</td>\n",
       "      <td>1.037540</td>\n",
       "      <td>0.478980</td>\n",
       "      <td>0.830336</td>\n",
       "      <td>-0.849844</td>\n",
       "      <td>...</td>\n",
       "      <td>0.756989</td>\n",
       "      <td>-0.793714</td>\n",
       "      <td>-0.528785</td>\n",
       "      <td>0.071566</td>\n",
       "      <td>-0.269875</td>\n",
       "      <td>-0.510016</td>\n",
       "      <td>-0.856084</td>\n",
       "      <td>-0.922165</td>\n",
       "      <td>geocentric</td>\n",
       "      <td>0.946218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>-0.803179</td>\n",
       "      <td>warranty</td>\n",
       "      <td>-0.271124</td>\n",
       "      <td>bay</td>\n",
       "      <td>1.492689</td>\n",
       "      <td>-0.998385</td>\n",
       "      <td>-0.226479</td>\n",
       "      <td>-0.877983</td>\n",
       "      <td>0.766080</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.021367</td>\n",
       "      <td>2.368674</td>\n",
       "      <td>1.170775</td>\n",
       "      <td>-0.100154</td>\n",
       "      <td>0.913585</td>\n",
       "      <td>0.367366</td>\n",
       "      <td>1.226933</td>\n",
       "      <td>-0.747212</td>\n",
       "      <td>Riviera</td>\n",
       "      <td>-2.654613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>-0.305225</td>\n",
       "      <td>inveigle</td>\n",
       "      <td>-0.186971</td>\n",
       "      <td>nod</td>\n",
       "      <td>-0.609512</td>\n",
       "      <td>0.028181</td>\n",
       "      <td>0.010353</td>\n",
       "      <td>1.390208</td>\n",
       "      <td>1.085896</td>\n",
       "      <td>-0.009119</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056650</td>\n",
       "      <td>-1.648321</td>\n",
       "      <td>0.735948</td>\n",
       "      <td>-0.025027</td>\n",
       "      <td>-1.065114</td>\n",
       "      <td>-1.311836</td>\n",
       "      <td>0.474698</td>\n",
       "      <td>0.529693</td>\n",
       "      <td>zag</td>\n",
       "      <td>1.203166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          17           leg_1         7        arm_2         2        11  \\\n",
       "88  1.846707        lapelled -0.359292       smutty  0.583928 -0.033127   \n",
       "37  1.236093        selenium  0.609138   peripheral  1.091310 -0.705012   \n",
       "8   0.959271         headmen -0.767348     Aventine  2.153182 -0.108760   \n",
       "83 -0.603985         stratus -0.155677        bract  0.086590  1.006293   \n",
       "33 -0.415288            test  2.270693     foothold  0.632782  0.018418   \n",
       "31 -0.553588     coprocessor  1.628397   deconvolve  0.568983  0.043811   \n",
       "15 -0.353166           Debby -0.295401      chimney  0.338484 -0.079641   \n",
       "39 -1.438278           shrub -0.668144        Erich  0.919229 -0.291811   \n",
       "99  0.992042        walkover -0.755745        young -0.174960  0.388579   \n",
       "85 -1.356582            calf -0.035641   percussion  0.466430 -2.424240   \n",
       "27  1.909417           scion  0.562969     invasion -1.398568 -0.007973   \n",
       "86  0.546734   fragmentation -0.366824       Reagan -0.238932 -1.006543   \n",
       "71 -0.977555              SW  0.751387        value  0.099332 -0.592394   \n",
       "74  1.187679           Exxon  0.201160     shamrock -0.464617  1.615376   \n",
       "60 -0.303180       tribesman -1.616311        fleet  0.799942  0.738810   \n",
       "4  -0.968344         inkling -1.334025      kingpin  0.105376 -0.988591   \n",
       "13 -0.288659     amethystine -0.827231    heartfelt  0.322719 -1.448084   \n",
       "34 -0.487911   transshipping -0.605715     Rockwell  2.157308 -0.172946   \n",
       "54  2.252436       patrolled -0.324831       cantle  0.981765 -1.096275   \n",
       "66 -0.971614           bowie -0.656894        Pablo  1.200414  1.301741   \n",
       "70 -0.083106            lulu  0.760056     airborne -1.504720  0.043602   \n",
       "57 -2.198806       objectify -0.502054        their  0.440014  0.132970   \n",
       "84  0.243339  multiplicative  0.352055   otherworld -0.241236  0.243801   \n",
       "82  0.186609            Iran  0.194090     warplane -0.446434 -1.359856   \n",
       "76  1.001046        runabout  0.677875    certitude -2.703232  0.950308   \n",
       "47 -1.211016         wattage  0.047399         horn -0.651836 -0.662624   \n",
       "43 -0.202193        disburse  1.098777   encryption -0.217681  0.812862   \n",
       "3  -0.689188       woodchuck  0.197911   systematic  1.735964  0.059630   \n",
       "25  1.752270         Textron  1.271555  equidistant  0.935678 -0.254977   \n",
       "30 -0.224765        Berniece -1.801980       banish -1.170113 -0.388177   \n",
       "77 -0.978764     ineluctable  0.377300  metallurgic -0.444293 -0.459361   \n",
       "53 -0.803179        warranty -0.271124          bay  1.492689 -0.998385   \n",
       "98 -0.305225        inveigle -0.186971          nod -0.609512  0.028181   \n",
       "\n",
       "           4        16         0        14  ...        12        10        15  \\\n",
       "88 -0.489439  2.526932 -0.517611  1.794558  ...  0.590655  0.068456 -1.371117   \n",
       "37 -0.111226  0.169361  0.558327 -0.055769  ... -1.092313 -2.281386  0.460938   \n",
       "8   0.024510  0.097676  0.690144  0.401712  ...  0.872321 -2.009185 -1.248690   \n",
       "83       NaN -2.471645       NaN -0.576892  ...  1.167782 -0.575002 -0.149518   \n",
       "33 -1.478586  0.235615  0.326927  1.676437  ...  0.181866 -2.003477 -1.373141   \n",
       "31 -0.803675 -0.088282  0.963879 -0.147002  ... -0.379128 -1.820377  0.655741   \n",
       "15  0.579633  1.187386 -1.062394       NaN  ...  0.168461  2.529834  0.884395   \n",
       "39 -0.426358  0.298753  0.883110       NaN  ...  1.873298  1.572337  0.778140   \n",
       "99       NaN  0.919076 -0.006071  2.493000  ...  0.536510 -1.755186  0.717686   \n",
       "85  0.794265 -1.562546  0.736844  0.884045  ... -1.615132  0.480502  0.308773   \n",
       "27 -0.875618 -1.037246  0.077368       NaN  ... -0.650643 -1.098317 -0.397696   \n",
       "86 -0.999302  1.296995  1.317115  1.139879  ... -0.391758  0.680573  0.631746   \n",
       "71 -0.576771 -0.238948  0.048522 -0.863991  ... -1.669405 -1.693028 -0.838070   \n",
       "74 -0.903702  0.403730  1.217159 -0.322320  ...  0.283288  0.964233  0.193754   \n",
       "60       NaN  0.367287 -0.935439  0.615367  ... -1.053682 -0.150138 -0.053969   \n",
       "4  -0.982487 -0.989628  0.179894 -1.103589  ... -0.601368 -0.348985  1.303736   \n",
       "13 -0.019016  0.857660       NaN -1.407464  ...  0.519347 -1.360456 -0.941163   \n",
       "34 -0.605616 -0.669073 -1.371901  1.711708  ...  0.742095 -0.782841  1.137462   \n",
       "54       NaN -0.638962  1.594505 -1.440051  ... -2.499406 -1.032233  0.996309   \n",
       "66 -0.365322  2.013387  0.032004  1.561511  ... -1.046911 -2.026321  0.552535   \n",
       "70 -0.429302 -0.611769 -0.622649  1.695051  ...  0.082440  1.279890  0.663523   \n",
       "57 -0.555200  1.565524  1.195047 -0.700121  ... -1.021233  1.537036 -0.798648   \n",
       "84 -1.525525  1.846637       NaN -0.564079  ...       NaN  1.560704 -0.722168   \n",
       "82 -0.095296  0.249384  0.645484  0.746254  ...  1.073632  0.826007 -1.027544   \n",
       "76  0.975198 -0.927353       NaN       NaN  ... -0.654076  1.372711  0.500477   \n",
       "47       NaN  0.259723 -0.763259  0.570599  ...       NaN -1.559849 -1.113279   \n",
       "43  1.277665 -0.020902       NaN  0.629629  ...  0.825416 -1.411759 -0.844677   \n",
       "3   1.317394  1.049553  0.698223 -0.646937  ... -0.651418  0.852392 -1.106450   \n",
       "25       NaN -0.342688       NaN  1.503993  ...       NaN  1.154661 -1.032605   \n",
       "30 -2.553921  0.949554  0.160574  0.170416  ...       NaN -0.808045  1.134462   \n",
       "77  1.037540  0.478980  0.830336 -0.849844  ...  0.756989 -0.793714 -0.528785   \n",
       "53 -0.226479 -0.877983  0.766080       NaN  ... -0.021367  2.368674  1.170775   \n",
       "98  0.010353  1.390208  1.085896 -0.009119  ...  0.056650 -1.648321  0.735948   \n",
       "\n",
       "           9        19        18         8         6        arm_0         1  \n",
       "88 -0.016423  0.681891  1.044161  0.223788  1.108704         heft  0.506885  \n",
       "37  0.538756 -0.735530 -0.903908  0.076005 -0.316408  ineffective  1.896911  \n",
       "8   0.224092  1.451144  0.497998 -0.401220  0.183342        stank  2.357902  \n",
       "83  0.529804  0.371146 -0.203045 -1.129707  0.254421          sat  0.588465  \n",
       "33  0.829406  0.338496  1.143754 -0.219101  0.248221    appliance  2.404373  \n",
       "31 -0.557492  1.677701  1.639117  2.210523 -0.203580     shopworn  1.393983  \n",
       "15 -0.187144  0.194384  0.325796  0.428307  1.317598    inferring -2.683180  \n",
       "39 -0.180480  0.113270  1.148446 -0.077837  1.080048          yuh -1.762549  \n",
       "99  0.081829 -0.668090  0.321698  0.838491 -0.898468     Brighton  1.308576  \n",
       "85  0.066991  0.293558 -1.254289 -0.281328  1.164739      earthen -0.568113  \n",
       "27  1.523124  0.926178 -1.382800 -0.861284 -0.487125    moneymake  1.170598  \n",
       "86 -2.121855  0.840620 -0.504775 -0.118069 -0.922410    bifurcate -0.885418  \n",
       "71  0.270457  0.500917  0.755391 -0.830950  0.543360    neuralgia  1.897924  \n",
       "74  0.998311 -1.179040  0.324359  1.521316 -0.258905   commissary -0.963142  \n",
       "60 -0.535963 -0.019420 -0.349317  1.085982 -1.067803       plural  0.159855  \n",
       "4   0.918317  0.550052 -0.224633  1.392002  0.319782  compensable -0.222100  \n",
       "13  0.310908 -0.018513 -1.002529 -0.213447  1.532739        Kabul  1.636312  \n",
       "34  1.471170  0.677926  1.826010 -1.613561  0.299293         Noah  0.244121  \n",
       "54 -0.991392 -0.688150  1.009817 -0.846961  2.290943       nature  0.531047  \n",
       "66  0.459972 -1.347126  0.184680 -0.753418  0.536653       dyeing  1.625375  \n",
       "70 -0.742471 -1.406317 -0.692421  0.194607 -1.457551       upkeep -1.447232  \n",
       "57 -0.558922 -1.448014  1.881157 -1.523187  0.708356      Clausen -1.075251  \n",
       "84  0.650201 -0.045586 -0.691908  0.872457  1.443765    frambesia -1.128686  \n",
       "82 -0.307778  0.607897  0.279022  2.163255 -1.026515       choosy -0.329294  \n",
       "76  0.070052  0.189582  0.501094 -0.168822 -1.830633        cacao -1.464473  \n",
       "47 -1.627542 -0.066080 -1.661520 -1.804882 -0.384556   everything  1.890331  \n",
       "43  0.747294  0.547097 -0.591571 -0.560181  0.813510         numb  1.643195  \n",
       "3   0.895193  2.075261  0.197600  0.393485 -0.483886       semper -0.320670  \n",
       "25  1.246085 -1.110576 -0.777817  1.091507 -1.129052       Keenan -0.628041  \n",
       "30  0.436938 -1.366879  0.934320  0.003046  0.759155  emptyhanded  0.268438  \n",
       "77  0.071566 -0.269875 -0.510016 -0.856084 -0.922165   geocentric  0.946218  \n",
       "53 -0.100154  0.913585  0.367366  1.226933 -0.747212      Riviera -2.654613  \n",
       "98 -0.025027 -1.065114 -1.311836  0.474698  0.529693          zag  1.203166  \n",
       "\n",
       "[33 rows x 24 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do some data analysis here\n",
    "\n",
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-083359799dd294d6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "While crunching your data, you probably found two issues:\n",
    "\n",
    "1. There are 4 columns whose name starts with either `arm` or `leg` which are all filled with gibberish\n",
    "2. There are some values missing in some columns\n",
    "\n",
    "So, first things first, let's get rid of those columns through a Custom Transformer, so we can plug it in a Scikit Pipeline after."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-57e648bb4ed49423",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 3: Custom Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e9663ebd68ad68f8",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'fit_transform'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-7ba6ff91feda>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# YOUR CODE HERE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mRemoveLimbs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mRemoveLimbs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/prep-venv/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5272\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5273\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5274\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5276\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'fit_transform'"
     ]
    }
   ],
   "source": [
    "# Create a pipeline step called RemoveEvilColumns that removes any\n",
    "# column whose name starts with the string 'evil'\n",
    "\n",
    "# YOUR CODE HERE\n",
    "RemoveLimbs = X_train.fit_transform(X_train).columns\n",
    "RemoveLimbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-5c8634dcc19dd7e1",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'DataFrame' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-82c9da05fdd6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m### BEGIN TESTS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0m_hash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRemoveLimbs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'salt5'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'71443dfc3077d773d4c74e958dadf91dc2cc148a'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0m_hash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'arm'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'leg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRemoveLimbs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'salt6'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'ce45cf3759d2210f2d1315f1673b18f34e3ac711'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m### END TESTS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'DataFrame' object is not callable"
     ]
    }
   ],
   "source": [
    "### BEGIN TESTS\n",
    "assert _hash(sorted(RemoveLimbs().fit_transform(X).columns), 'salt5') == '71443dfc3077d773d4c74e958dadf91dc2cc148a'\n",
    "assert _hash(list(map(lambda col: col.startswith('arm') or col.startswith('leg'), RemoveLimbs().fit_transform(X_train).columns)), 'salt6') == 'ce45cf3759d2210f2d1315f1673b18f34e3ac711'\n",
    "### END TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e0ded8876cfda9aa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<img src=\"media/monty_python_black_knight.gif\" width=500>\n",
    "\n",
    "Now that we have our Custom Transformer in place, we can design our pipeline. For the sake of the exercise, you'll want to create a pipeline with the following steps:\n",
    "\n",
    "1. Removes limbs columns\n",
    "2. Imputes missing values with the mean\n",
    "3. Has a Random Forest Classifier as the last step\n",
    "\n",
    "You may use `make_pipeline` to create your pipeline with as many steps as you want as long as the first two are the Custom Transformer you developed previously, a `SimpleImputer` as the second step, and a `RandomForestClassifier` as the last step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b18993e1e6a77d8c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 4: Scikit Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-efabb79e960ce10b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-6814224bb0f1332f",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN TESTS\n",
    "assert _hash(pipeline.steps[0][0], 'salt7') == '471b02068ac2c4f479c2e9f85f4b3dc2179bb841'\n",
    "assert _hash(pipeline.steps[1][0], 'salt8') == 'ca83eaea1a7e243fa5574cfa6f52831166ee0f32'\n",
    "assert _hash(pipeline.steps[-1][0], 'salt9') == '0d66ba4309ad4939673169e74f87088dcadd510b'\n",
    "### END TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-53269c4aaa5f3df3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Does it work? Let's check it out on our dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-dd7deb2b78d36444",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d4defdb6d3d670ae",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "y_pred = pipeline.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1e887f18b73a6081",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "That's it for this Exercise Notebook! It doesn't get much cleaner than this, does it?\n",
    "\n",
    "You can still practice around with pipelines, maybe add a few more steps. See how you can adapt your pipeline and how it affects the predictions.\n",
    "\n",
    "Can you see how Scikit-learn's Pipelines might save time? Can you imagine how useful that would be in stressful situations (like, *for example*, an Hackathon)?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
